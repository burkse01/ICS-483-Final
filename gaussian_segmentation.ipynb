{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone --recursive https://github.com/camenduru/gaussian-splatting\n",
    "!pip install -q plyfile\n",
    "!pip install torch-points3d\n",
    "\n",
    "%cd /content/gaussian-splatting\n",
    "!pip install -q /content/gaussian-splatting/submodules/diff-gaussian-rasterization\n",
    "!pip install -q /content/gaussian-splatting/submodules/simple-knn\n",
    "\n",
    "!wget https://huggingface.co/camenduru/gaussian-splatting/resolve/main/tandt_db.zip\n",
    "!unzip tandt_db.zip\n",
    "\n",
    "!python train.py -s /content/gaussian-splatting/tandt/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_write_model import read_model\n",
    "\n",
    "cam_intrinsics, images_metas, points3d = read_model(path)\n",
    "\n",
    "pts_indices = np.array([points3d[key].id for key in points3d])\n",
    "pts_xyzs = np.array([points3d[key].xyz for key in points3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.applications.pointnet2 import PointNet2\n",
    "import torch\n",
    "\n",
    "pn_model = PointNet2(\n",
    "    \"segmentation\",\n",
    "    input_nc=3,  # Number of input features \n",
    "    num_classes=16,  # Number of segmentation classes \n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "pn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = pn_model(point_cloud)  # Shape: (batch_size, num_points, num_classes)\n",
    "for classes in outputs[::3]:\n",
    "    #Save Individual Segments to be viewed\n",
    "    #highlight in original image\n",
    "\n",
    "\n",
    "predicted_labels = torch.argmax(outputs, dim=-1)  # Shape: (batch_size, num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scene.dataset_readers import storePly\n",
    "storePly(path, xyz, rgb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
